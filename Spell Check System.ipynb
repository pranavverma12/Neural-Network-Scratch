{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2oP1uun77cIh"
   },
   "source": [
    "# Description\n",
    "\n",
    "In thiks project I am going to create spell checking system and evaluate its performance.\n",
    "\n",
    "For the dataset I am using `holbrook.txt` file.\n",
    "\n",
    "The file consists of lines of text, with one sentence per line. Errors in the line are marked with a `|` as follows\n",
    "\n",
    "    My siter|sister go|goes to Tonbury .\n",
    "    \n",
    "In this case the word 'siter' was corrected to 'sister' and the word 'go' was corrected to 'goes'.\n",
    "\n",
    "In some places in the corpus two words maybe corrected to a single word or one word to a multiple words. This is denoted in the data using underscores e.g.,\n",
    "\n",
    "    My Mum goes out some_times|sometimes .\n",
    "\n",
    "*Note: We are using NLTK libraries. It should not be necessary to use other libraries, but currenly I am focusing on NLTK.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TIVCSJV-7kDs"
   },
   "source": [
    "## Task 1\n",
    "\n",
    "We are writting a parser that can read all the lines of the file `holbrook.txt` and print out for each line the original (misspelled) text, the corrected text and the indexes of any changes. The indexes refers to the index of the words in the sentence. \n",
    "In the example given, there is only an error in the 10th word and so the list of indexes is [9]. It is not necessary to analyze where the error occurs inside the word.\n",
    "\n",
    "Then split your data into a test set of 100 lines and a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "TzaUSnBeREWt",
    "outputId": "89f29260-20c9-47f4-a53f-86dafbefa1ec"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "uploaded = files.upload()\n",
    "\n",
    "#To solve the error \"initial_value must be unicode or None, not str\" decode is used\n",
    "lines = io.StringIO(uploaded['holbrook.txt'].decode('utf-8')).readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17054
    },
    "colab_type": "code",
    "id": "FCGU8tFZqFgW",
    "outputId": "be75af0e-7a66-4bcc-ec94-d43e1712b5db",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4131
    },
    "colab_type": "code",
    "id": "-8Hz__UBS2wQ",
    "outputId": "3f3aa5b2-085a-4c1f-806a-3ded319c937d"
   },
   "outputs": [],
   "source": [
    "import nltk as nk\n",
    "nk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RznCZ1mw7mfk"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "#Seprating the words into corrected and originals. Also stroing the indexes of the words.\n",
    "for i in range(len(lines)):\n",
    "    if \"|\" in lines[i]:\n",
    "        lines_in_arr = nk.word_tokenize(lines[i].encode('ascii', 'ignore'))\n",
    "        initial_data = {\n",
    "            'original': list(lines_in_arr),\n",
    "            'corrected': list(lines_in_arr),\n",
    "            'indexes': []\n",
    "        }\n",
    "        for j in initial_data['original']:\n",
    "          if(\"|\" in j) == True:\n",
    "            index_correction = initial_data['original'].index(j)\n",
    "            correction_values = j.split(\"|\")\n",
    "            initial_data['corrected'][index_correction] = correction_values[1]\n",
    "            initial_data['original'][index_correction] = correction_values[0]            \n",
    "            initial_data['indexes'].append(index_correction)\n",
    "        data.append(initial_data)                \n",
    "    else:\n",
    "        initial_data = {\n",
    "            'corrected' : nk.word_tokenize(lines[i].encode('ascii', 'ignore')),\n",
    "            'original': nk.word_tokenize(lines[i].encode('ascii', 'ignore'))\n",
    "        }\n",
    "        data.append(initial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "JwL2YgOlpWhW",
    "outputId": "e31cba8b-699e-4bc6-f030-8bd3c81f4682"
   },
   "outputs": [],
   "source": [
    "print(data[164])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eRSX4I0H7pSC"
   },
   "source": [
    "The counts and assertions given in the following sections are based on splitting the training and test set as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kt9aR2Gy7p1C"
   },
   "outputs": [],
   "source": [
    "test = data[:100]\n",
    "train = data[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hm5JL7cH7sLK"
   },
   "source": [
    "## **Task 2**: \n",
    "Calculate the frequency (number of occurrences), *ignoring case*, of all words and their unigram probability from the corrected *training* sentences.\n",
    "\n",
    "*Using `Counter` to implement this so it may be called many times*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "31kEYJn3l9kg",
    "outputId": "5f273a35-9633-4d2f-dc10-5bc3b50535cd"
   },
   "outputs": [],
   "source": [
    "#Creating filtering training data\n",
    "filtering_training_data = []\n",
    "for tr in range(len(train)):\n",
    "    filtering_training_data = filtering_training_data + train[tr][\"corrected\"]\n",
    "print(filtering_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ge0uHS-7uEK"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#Calculating Unigram for a word.\n",
    "def unigram(word):   \n",
    "    count_of_word = Counter(w.lower() for w in filtering_training_data)\n",
    "    return count_of_word[word.lower()]\n",
    "    \n",
    "#Calculating the probability of a word.\n",
    "def prob(word):\n",
    "    count = unigram(word)\n",
    "    total = 0\n",
    "    for w in filtering_training_data:        \n",
    "        total += 1\n",
    "    return float(count)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "1KfmLr8EKIfi",
    "outputId": "83d2cc52-8320-404f-ae9d-904ffa7e2d9a"
   },
   "outputs": [],
   "source": [
    "print(unigram(\"ME\"))\n",
    "print(unigram(\"the\"))\n",
    "print(prob(\"the\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8r8QYj78GPK"
   },
   "source": [
    "## **Task 3**: \n",
    "[Edit distance](https://en.wikipedia.org/wiki/Edit_distance) is a method that calculates how similar two strings are to one another by counting the minimum number of operations required to transform one string into the other. There is a built-in implementation in NLTK that works as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SV9Mu8P38IQE",
    "outputId": "587e9473-5869-4fce-fbc6-9d6373fe4e62"
   },
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "\n",
    "# Edit distance returns the number of changes to transform one word to another\n",
    "print(edit_distance(\"hello\", \"hi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hm46Lbiz8K8M"
   },
   "source": [
    "Writting a function that calculates all words with *minimal* edit distance to the misspelled word. You should do this as follows\n",
    "\n",
    "1. Collect the set of all unique tokens in `train`\n",
    "2. Find the minimal edit distance, that is the lowest value for the function `edit_distance` between `token` and a word in `train`\n",
    "3. Output all unique words in `train` that have this same (minimal) `edit_distance` value\n",
    "\n",
    "*Using the built-in NLTK function `edit_distance`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HoilAmFW8PCb",
    "outputId": "24c0c7fe-12ca-479a-cb29-172cf8189fc8"
   },
   "outputs": [],
   "source": [
    "#Finding the distance between wrong and the predicted correct word(s).\n",
    "def get_candidates(token):\n",
    "    word_distance = []\n",
    "    all_word_distance = []\n",
    "    min_distance = 0\n",
    "    result = []\n",
    "    all_unqiue_words = set(filtering_training_data)\n",
    "    for y in all_unqiue_words:\n",
    "        word_distance = {\n",
    "            \"word\":  y,\n",
    "            \"distance\": edit_distance(y, token)\n",
    "        }\n",
    "        all_word_distance.append(word_distance)\n",
    "        if min_distance == 0:\n",
    "            min_distance = word_distance['distance']\n",
    "        elif word_distance['distance'] <= min_distance:\n",
    "            min_distance = word_distance[\"distance\"]\n",
    "\n",
    "    for j in all_word_distance:\n",
    "        if j[\"distance\"] == min_distance:\n",
    "            result.append(j[\"word\"])\n",
    "    return result\n",
    "        \n",
    "# Test your code as follows\n",
    "get_candidates(\"minde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGY-eCkN8TIM"
   },
   "source": [
    "## Task 4:\n",
    "\n",
    "Writting a function that takes a (misspelled) sentence and returns the corrected version of that sentence. The system should scan the sentence for words that are not in the dictionary (set of unique words in the training set) and for each word that is not in the dictionary choose a word in the dictionary that has minimal edit distance and has the highest *unigram probability*. \n",
    "\n",
    "*Your solution to this should involve `get_candidates`*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIGKE4_P8WGP"
   },
   "outputs": [],
   "source": [
    "#Correcting the word in a sentence.\n",
    "def correct(sentence):\n",
    "    split_sentence = sentence\n",
    "    all_predicted_words = []\n",
    "    prob_all_predicted_words = []\n",
    "    mispelled_words = [i for i in split_sentence if i not in set(filtering_training_data)]\n",
    "    \n",
    "    for word in mispelled_words:\n",
    "        predicted_words = get_candidates(word)\n",
    "        for pw in predicted_words:\n",
    "            predicted_word = {\n",
    "                \"word\": pw,\n",
    "                \"probability\": prob(pw)\n",
    "            }\n",
    "            all_predicted_words.append(predicted_word)\n",
    "        for apw in all_predicted_words:\n",
    "            prob_all_predicted_words.append(apw[\"probability\"])\n",
    "        max_word_prob = max(prob_all_predicted_words)\n",
    "        split_sentence[split_sentence.index(word)] = [t[\"word\"].lower() for t in all_predicted_words if t[\"probability\"] == max_word_prob][0]\n",
    "    return split_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IKqZ_LUvp2TC",
    "outputId": "81023a90-494c-41b7-f64b-dd0240ebd5c5"
   },
   "outputs": [],
   "source": [
    "print(correct([\"this\",\"whitr\",\"ct\"]))\n",
    "print(correct([\"Enfield\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oG7jC6au8kka"
   },
   "source": [
    "## **Task 5**: \n",
    "Using the test corpus evaluate the *accuracy* of your method, i.e., how many words from your system's output match the corrected sentence (you should count words that are already spelled correctly and not changed by the system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jYvVuZVz-qln"
   },
   "outputs": [],
   "source": [
    "original_test_data = []\n",
    "corrected_test_data = []\n",
    "check_correct_words = []\n",
    "correct_counter = []\n",
    "incorrect_counter = []\n",
    "for te in range(len(test)):\n",
    "    if 'original' in test[te]:\n",
    "        original_test_data = original_test_data + test[te]['original']\n",
    "for te in range(len(test)):\n",
    "  corrected_test_data = corrected_test_data + test[te]['corrected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "oYMFobND-kkp",
    "outputId": "446c1486-955d-46ab-d946-137c84c73bb5"
   },
   "outputs": [],
   "source": [
    "print(len(corrected_test_data))\n",
    "print(len(original_test_data))\n",
    "print(corrected_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "HSXTQypR8mdR",
    "outputId": "238d20ac-1d62-4eae-eed9-0f8389bfe142"
   },
   "outputs": [],
   "source": [
    "#Calculating the accuracy of our system.\n",
    "def accuracy(test):  \n",
    "    check_correct_words = correct(original_test_data)    \n",
    "    for cword in range(len(check_correct_words)):\n",
    "      if check_correct_words[cword] == corrected_test_data[cword]:\n",
    "        correct_counter.append(check_correct_words[cword])\n",
    "      else:\n",
    "        incorrect_counter.append(check_correct_words[cword])\n",
    "    calc_accuracy = float(len(correct_counter))/len(check_correct_words)\n",
    "    \n",
    "    print(\"TRUE \",len(correct_counter))\n",
    "    print(\"FALSE \",len(incorrect_counter))\n",
    "    print(incorrect_counter)\n",
    "    print(set(correct_counter))\n",
    "    return calc_accuracy\n",
    "\n",
    "print(accuracy(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9b-r2JzD8_Zh"
   },
   "source": [
    "## **Task 6:**\n",
    "\n",
    "Consider a modification to your algorithm that would improve the accuracy of the algorithm developed in Task 3 and 4\n",
    "\n",
    "* You may resources beyond those provided here.\n",
    "* You must **not use the test data** in this task.\n",
    "* Provide a short text describing what you intend to do and why. \n",
    "* Full marks for this section may be obtained without an implementation, but an implementation is preferred.\n",
    "* Your implementation should not consist of more than 50 lines of code\n",
    "\n",
    "Please note this task is marked according to: demonstration of knowledge from the lecutures (10), originality and appropriateness of solution (10), completeness of description (10) and technical correctness (5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Omxq2Cx4C40r"
   },
   "source": [
    "\n",
    "**In the current algorithm:**\n",
    "\n",
    "We are sending the original test data (words containing correct and misspelled) into a correct function, which will filter out all misspelled word and then run the loop to calculate the distance of misspelled word with nearly correct words in data set.  After getting the list of maybe corrected words we will take out their probability using unigram and replace the misspelled word with the max probability of correct word. If, there is a tie between the distance and probability of two words we are explicitly taking the first correct word in the result array. Once we get the correct sentence, we are comparing the result with the test correct sentences to find out the accuracy of an algorithm. The accuracy of the first algorithm is **78.69%.** \n",
    "\n",
    "I think, there is some flaw in the first algorithm. To try to improve the accuracy and improve my first algorithm. I found out some other effective algorithms (which are taught in the class) which are: \n",
    "\n",
    "  **1. Bigram:**\n",
    "\n",
    "  -\tMany times words repeat themselves in pairs like (good, work), (they, go) etc. If we need to identify such pairs of words which will help us in sentiment analysis. To do this, we will generate such word pairs from the given corpus or sentences preserving their sequences. These pairs are called bigrams. \n",
    "  \n",
    "  -\tIn python nltk, we have an inbuilt function for same. I.e. nltk.bigrams() and to calculate probability we can use another inbuild function of nltk function ConditionalFreqDist, using this we can find the probability.\n",
    " \n",
    "  **2.\tHMM:**\n",
    "\n",
    "  -\tIt is mainly used for the analysis of sequence data and is widely used in many fields like speech recognition, gene prediction, pos tagging, text translation, sequence prediction and time series analysis.\n",
    "  \n",
    "  -\tIt is the most efficient but it takes start probabilities (as per my understating which is given by the user) so we cannot use this model.\n",
    "\n",
    "  **3.\tPOS Tagging:**\n",
    "  \n",
    "  -\tParts of speech (POS) tagging means that distribution grammatical classes i.e. appropriate elements of speech tags to every word in a very natural language sentence.  \n",
    "  \n",
    "  -\tThe process takes a word or a sentence as input, assigns a POS tag to the word or to each word within the sentence, and produces the tagged text as output. \n",
    "  \n",
    "  -\tPOS tagging can be employed in Text to Speech (TTS) applications, information retrieval, parsing, \n",
    "information extraction, linguistic research for corpora and also will be used as an intermediate step for higher level NLP tasks such as parsing, semantic analysis, translation, and many additional, which \n",
    "makes POS tagging a necessary function for advanced NLP applications. \n",
    "\n",
    "  -\tPOS tagging is useful for syntactical parsing as taggers scale back ambiguity from the parser's input sentence, which makes parsing quicker by creating the computational drawback smaller, and the result less ambiguous. It also resolves some ambiguities that are not addressed by the syntactical parser’s language model.\n",
    "\n",
    "  **4.\tSmoothing Methods:**\n",
    "  \n",
    "  -\tIn add-one smoothing, we add values in the numerator and denominator so that while calculating the probability of some word we will not get the zero probability even if the word is not available in the given sentence or corpus. \n",
    "\n",
    "### Modified Algorithm:\n",
    "\n",
    "-\tAfter checking through the process of all the above different algorithms/methods I decide to go ahead with the POS Tagging because I believe that it will be helpful in increasing the accuracy as is it tagging each word with nouns, verbs, determinant, cardinal number etc. so it will beneficial for us to ignore the cardinal numbers and pronouns. \n",
    "\n",
    "-\t***For example***, in my first algorithm if a sentence contains a word “THRUSH” it will be converted to “house” as the house will have the maximum probability. But that should not happen, as “THRUSH” is a pronoun and has special meaning in the sentence, while the replaced word house don’t make any meaning in the sentence. Similarly, cardinal number “48” is getting converted into “4” maybe cardinal number has some meaning in the sentence and while converting that we are losing the correctness and meaning of the sentence.  \n",
    "\n",
    "-\tIn addition to, in first algorithm we are not aware of the thing that the word is converting to which part of speech, but in the modified version we can check that out too.\n",
    "\n",
    "For testing this and to check the accuracy we have done the pos tagging on test original data set and we are passing it to the unchanged correct function. Once the words gets corrected we are checking if the word has either “CD” or “NNP” tag. If they have we are ignoring them (assuming them as a correct). Than calculating the accuracy accordingly by using the formula i.e. no of correct word prediction/total number of words. \n",
    "\n",
    "Hence, after using POS tagging we are getting an accuracy of **90.05 %**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GLzaC6D28sK9"
   },
   "source": [
    "## **Task 7:**\n",
    "\n",
    "Repeating the evaluation (as in Task 5) of your new algorithm and show that it outperforms the algorithm from Task 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTdwd8O_LdeP"
   },
   "outputs": [],
   "source": [
    "tpd = []\n",
    "for tr in range(len(test)):  \n",
    "  x = \" \".join(test[tr][\"original\"])\n",
    "  tpd = tpd + nk.pos_tag(nk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-L1OJP2HGj98",
    "outputId": "b8cea1be-d808-498b-b6bd-2d227ef00d43"
   },
   "outputs": [],
   "source": [
    "print(tpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Tlo98jg6AklA",
    "outputId": "153ed7b1-a18b-40ce-c3d7-d323558c5d82"
   },
   "outputs": [],
   "source": [
    "cx = [wx for wx, px in tpd]\n",
    "print(len(cx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXqDetWKdJnj"
   },
   "outputs": [],
   "source": [
    "correct_counter = []\n",
    "incorrect_counter = []\n",
    "def accuracy1(test):\n",
    "    check_correct_words = correct(cx)\n",
    "    for cword in range(len(check_correct_words)):      \n",
    "      if ((tpd[cword][1] == 'CD') | (tpd[cword][1] == 'NNP') | (tpd[cword][0] == corrected_test_data[cword])):\n",
    "        correct_counter.append(tpd[cword][0])  \n",
    "      else:\n",
    "        incorrect_counter.append(tpd[cword][0])\n",
    "    calc_accuracy = float(len(correct_counter))/len(check_correct_words)\n",
    "    print(\"TRUE \",len(correct_counter))\n",
    "    print(\"FALSE \",len(incorrect_counter))\n",
    "    print(incorrect_counter)\n",
    "    print(correct_counter)\n",
    "    print(len(check_correct_words))\n",
    "    return calc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "okHPp4SjB2nz",
    "outputId": "93b3b4b1-e06e-47b2-9fe1-7abe1d084325"
   },
   "outputs": [],
   "source": [
    "print(accuracy1(test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "18230141_NLP_18_19_Assignment_1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
